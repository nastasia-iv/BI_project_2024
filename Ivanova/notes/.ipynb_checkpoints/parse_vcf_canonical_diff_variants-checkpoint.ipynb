{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc565154-10df-46fa-a441-bb2e1e42e3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# Прописать путь сохранения аутпута, если указано название нового файла (по дефотлу сохраняется в папку с парсером)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ed41d0b-9560-49c8-a5fc-2bd1dec9afc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b8386a-ffba-489d-8654-a54d619a0a9c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# headers = ['Chr', 'Position', 'rsID', 'Ref', 'Alt', 'Consequence', 'Canonical',\n",
    "#            'Gene_symbol', 'LoF', 'LoF_flag', 'LoF_filter',\n",
    "#            'AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', 'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "#            'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "#            'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9c9e99f-97f3-48b6-9717-925608d3ee1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['Chr', 'Position', 'rsID', 'Ref', 'Alt', 'AC',\n",
    "           'Impact', 'Consequence', 'Gene_symbol', \n",
    "           'Canonical_transcript', 'cDNA_position', \n",
    "           'LoF', 'LoF_flag', 'LoF_filter'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8fe0434-810e-4795-9d00-e9771f851097",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "vcf_field_mapping = dict(zip(vcf_columns, range(len(vcf_columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69aac573-eb49-4370-a9e8-17d2d16d46b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vep_field_names = 'Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|ALLELE_NUM|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|MANE_SELECT|MANE_PLUS_CLINICAL|TSL|APPRIS|CCDS|ENSP|UNIPROT_ISOFORM|SOURCE|DOMAINS|miRNA|HGVS_OFFSET|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS|LoF|LoF_filter|LoF_flags|LoF_info'.split('|')\n",
    "vep_field_names = 'Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|Protein_position|Amino_acids|Codons|ALLELE_NUM|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|MANE_SELECT|MANE_PLUS_CLINICAL|TSL|APPRIS|CCDS|ENSP|UNIPROT_ISOFORM|SOURCE|||DOMAINS|miRNA|HGVS_OFFSET|PUBMED|MOTIF_NAME|MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS|LoF|LoF_filter|LoF_flags|LoF_info'.split('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a52f684-429e-4b89-a7cd-49abc7f7981e",
   "metadata": {},
   "outputs": [],
   "source": [
    "population_data = {\n",
    "    'AC': None, 'AC_afr': None, 'AC_amr': None, 'AC_nfe': None, 'AC_asj': None, 'AC_sas': None, 'AC_eas': None, 'AC_mid': None, 'AC_fin': None,\n",
    "    'AN': None, 'AN_afr': None, 'AN_amr': None, 'AN_nfe': None, 'AN_asj': None, 'AN_sas': None, 'AN_eas': None, 'AN_mid': None, 'AN_fin': None,\n",
    "    'AF': None, 'AF_afr': None, 'AF_amr': None, 'AF_nfe': None, 'AF_asj': None, 'AF_sas': None, 'AF_eas': None, 'AF_mid': None, 'AF_fin': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "74dfa898-8857-45d5-bfdc-74551963d972",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# НЕ ИСПОЛЬЗУЕТСЯ\n",
    "# Функция для извлечения уникальных значений из нужных полей vep\n",
    "\n",
    "def get_unique_vep_info(line, target_field):\n",
    "    info_index = vcf_field_mapping['INFO']\n",
    "    column_with_info = line[info_index].split(';')  # делим все колонки vep по ;\n",
    "    vep_info = column_with_info[-1].split('|')\n",
    "\n",
    "    all_values = []\n",
    "    unique_values = set()\n",
    "\n",
    "    start_index = vep_field_names.index(target_field)\n",
    "    step = 47  # т.к. всего 46 полей в поле vep\n",
    "\n",
    "    for i in range(start_index, len(vep_info), step):\n",
    "        value = vep_info[i]\n",
    "        if value:  # проверяем, что значение не пустое\n",
    "            all_values.append(value)\n",
    "            unique_values.add(value)\n",
    "\n",
    "    return list(unique_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13c984cd-8261-4ed7-aca5-0cc398084235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для извлечения инфы только по каноническому транскрипту\n",
    "\n",
    "def get_canon_transcript_info(line, target_field):\n",
    "    info_index = vcf_field_mapping['INFO']\n",
    "    column_with_info = line[info_index].split(';')  # разделяем все поля VEP по ;\n",
    "    vep_info = column_with_info[-1].split('|')\n",
    "    transcript_info = []\n",
    "\n",
    "    target_field_index = vep_field_names.index(target_field)\n",
    "\n",
    "    symbol_index = vep_field_names.index('SYMBOL')\n",
    "    feature_index = vep_field_names.index('Feature')\n",
    "    canonical_index = vep_field_names.index('CANONICAL')\n",
    "\n",
    "    step = 47  # так как всего 46 полей в VEP\n",
    "\n",
    "    # Начинаем с индекса первого транскрипта и идем с шагом step\n",
    "    for i in range(feature_index, len(vep_info), step):\n",
    "        transcript = vep_info[i]\n",
    "        canonical = vep_info[i + canonical_index - feature_index]  # индекс относительно i\n",
    "        symbol = vep_info[i + symbol_index - feature_index]\n",
    "\n",
    "        # Берем канонический транскрипт\n",
    "        if symbol and transcript.startswith('ENST') and canonical:\n",
    "            info = vep_info[i + target_field_index - feature_index]\n",
    "            if info:  # оставляем только непустые значения\n",
    "                # не выводим сам транскрипт, если это не требуется напрямую\n",
    "                if target_field == 'Feature' or target_field == 'CANONICAL':\n",
    "                    transcript_info.append(transcript)\n",
    "                else:\n",
    "                    transcript_info.append(info)\n",
    "\n",
    "    return transcript_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32c4e084-7768-4462-a8e3-07daef986cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция для парсинга вцф-файла\n",
    "\n",
    "def get_parse_vcf(vcf_file, output_dir='', output_filename=''):\n",
    "\n",
    "    # Если папка не указана, сохраняем в текущую директорию\n",
    "    if output_dir == '':\n",
    "        output_dir = os.getcwd()\n",
    "    \n",
    "    # Если имя выходного файла не задано, используем имя входного файла, но с расширением .tsv\n",
    "    # Через basename получаем имя файла, а через splitext оставляем только название без расширения\n",
    "    if output_filename == '':\n",
    "        output_filename = os.path.splitext(os.path.basename(vcf_file))[0] + '.tsv'\n",
    "    else:\n",
    "        # Если не указано расширение файла (указано неверно), добавляем .tsv\n",
    "        if not output_filename.endswith('.tsv'):\n",
    "            output_filename += '.tsv'\n",
    "    \n",
    "    # Полный путь к выходному файлу\n",
    "    output_file = os.path.join(output_dir, output_filename)\n",
    "    \n",
    "    # Запись шапки таблицы в выходной файл\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as table_file:\n",
    "        writer = csv.writer(table_file, delimiter='\\t')\n",
    "        writer.writerow(headers)\n",
    "\n",
    "    # Открываем на чтение файл, который надо распарсить\n",
    "    with gzip.open(vcf_file, 'rt') as input_file, open(output_file, 'a', newline='', encoding='utf-8') as output_file:\n",
    "        vcf_reader = csv.reader(input_file, delimiter='\\t')\n",
    "        tsv_writer = csv.writer(output_file, delimiter='\\t')\n",
    "\n",
    "        for line in vcf_reader:\n",
    "            if line[vcf_field_mapping['CHROM']].startswith('chr'):\n",
    "                if line[vcf_field_mapping['FILTER']] == 'PASS':\n",
    "                    \n",
    "                    # Общая информация\n",
    "                    chrom = line[vcf_field_mapping['CHROM']]\n",
    "                    position = line[vcf_field_mapping['POS']]\n",
    "                    rsID = line[vcf_field_mapping['ID']]\n",
    "                    Ref = line[vcf_field_mapping['REF']]\n",
    "                    Alt = line[vcf_field_mapping['ALT']]\n",
    "\n",
    "                    # Популяционные данные\n",
    "                    info_index = vcf_field_mapping['INFO']\n",
    "                    column_with_info = line[info_index].split(';')\n",
    "                    for element in column_with_info:\n",
    "                        for category in population_data:\n",
    "                            if element.startswith(f'{category}='):\n",
    "                                frequency_value = element.split('=')\n",
    "                                population_data[category] = frequency_value[-1]  # забираем только численное значение  \n",
    "\n",
    "                    # Получаем характеристики канонических(!) транскриптов\n",
    "                    impact = get_canon_transcript_info(line, 'IMPACT')\n",
    "                    consequence = get_canon_transcript_info(line, 'Consequence')\n",
    "                    gene_symbol = get_canon_transcript_info(line, 'SYMBOL')\n",
    "                    canonical_ensembl = get_canon_transcript_info(line, 'Feature')\n",
    "                    cDNA_position = get_canon_transcript_info(line, 'cDNA_position')\n",
    "                    lof = get_canon_transcript_info(line, 'LoF')\n",
    "                    lof_flags = get_canon_transcript_info(line, 'LoF_flags')\n",
    "                    lof_filters = get_canon_transcript_info(line, 'LoF_filter')\n",
    "\n",
    "                    # Записываем новые данные в таблицу\n",
    "                    filtered_data = [\n",
    "                                    chrom, \n",
    "                                    position, \n",
    "                                    rsID, \n",
    "                                    Ref, \n",
    "                                    Alt,\n",
    "                                    population_data['AC'],\n",
    "                                    ', '.join(impact),\n",
    "                                    ', '.join(consequence),\n",
    "                                    ', '.join(gene_symbol),\n",
    "                                    ', '.join(canonical_ensembl),\n",
    "                                    ', '.join(cDNA_position),\n",
    "                                    ', '.join(lof),\n",
    "                                    ', '.join(lof_flags),\n",
    "                                    ', '.join(lof_filters)\n",
    "                    ]\n",
    "\n",
    "                    tsv_writer.writerow(filtered_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1fb059-5bab-49aa-b757-7fe5cb32df39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2a3682a-e66b-4427-9f01-9e382f8c6ba5",
   "metadata": {},
   "source": [
    "Указываем input файл (или путь к нему), а также имя output (необязательно, задаётся по умолчанию по названию вцф):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e2dd832-492d-4c76-a69a-67beecdcb710",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_parse_vcf('../raw_data/example_22chr.vcf.bgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "283bc135-3953-4238-9627-530558346c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chromosome_files = [f'gnomad.exomes.v4.0.sites.chr{i}.vcf.bgz' for i in range(1, 23)]\n",
    "\n",
    "# for file_name in chromosome_files:\n",
    "#     file_path = os.path.join('../raw_data', file_name)\n",
    "#     get_parse_vcf(file_path, output_dir='data_dir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fab97d-38a6-4c2c-b9e7-a76d7be36272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85c8432a-5aee-488e-aaf7-d6261a878f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "headers = [\n",
    "    'Chr', 'Position', 'rsID', 'Ref', 'Alt', 'AC', 'Impact', 'Consequence',\n",
    "    'Gene_symbol', 'Canonical_transcript', 'cDNA_position', 'LoF', 'LoF_flag', 'LoF_filter'\n",
    "]\n",
    "\n",
    "vcf_columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "vcf_columns_mapping = dict(zip(vcf_columns, range(len(vcf_columns))))\n",
    "\n",
    "vep_field_names = (\n",
    "    'Allele|Consequence|IMPACT|SYMBOL|Gene|Feature_type|Feature|BIOTYPE|EXON|INTRON|HGVSc|HGVSp|cDNA_position|CDS_position|'\n",
    "    'Protein_position|Amino_acids|Codons|ALLELE_NUM|DISTANCE|STRAND|FLAGS|VARIANT_CLASS|SYMBOL_SOURCE|HGNC_ID|CANONICAL|'\n",
    "    'MANE_SELECT|MANE_PLUS_CLINICAL|TSL|APPRIS|CCDS|ENSP|UNIPROT_ISOFORM|SOURCE|||DOMAINS|miRNA|HGVS_OFFSET|PUBMED|MOTIF_NAME|'\n",
    "    'MOTIF_POS|HIGH_INF_POS|MOTIF_SCORE_CHANGE|TRANSCRIPTION_FACTORS|LoF|LoF_filter|LoF_flags|LoF_info'\n",
    ").split('|')\n",
    "\n",
    "population_data = {\n",
    "    'AC': None, 'AC_afr': None, 'AC_amr': None, 'AC_nfe': None, 'AC_asj': None, 'AC_sas': None, 'AC_eas': None, 'AC_mid': None, 'AC_fin': None,\n",
    "    'AN': None, 'AN_afr': None, 'AN_amr': None, 'AN_nfe': None, 'AN_asj': None, 'AN_sas': None, 'AN_eas': None, 'AN_mid': None, 'AN_fin': None,\n",
    "    'AF': None, 'AF_afr': None, 'AF_amr': None, 'AF_nfe': None, 'AF_asj': None, 'AF_sas': None, 'AF_eas': None, 'AF_mid': None, 'AF_fin': None\n",
    "}\n",
    "\n",
    "\n",
    "def parse_vcf(vcf_file, output_dir='', output_filename=''):\n",
    "    if not output_dir:\n",
    "        output_dir = os.getcwd()\n",
    "\n",
    "    if not output_filename.endswith('.tsv'):\n",
    "        output_filename += '.tsv'\n",
    "\n",
    "    output_file = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as table_file:\n",
    "        writer = csv.writer(table_file, delimiter='\\t')\n",
    "        writer.writerow(headers)\n",
    "\n",
    "    with gzip.open(vcf_file, 'rt') as input_file:\n",
    "        vcf_reader = csv.reader(input_file, delimiter='\\t')\n",
    "\n",
    "        for line in vcf_reader:\n",
    "            if line[vcf_columns_mapping['CHROM']].startswith('chr') and line[vcf_columns_mapping['FILTER']] == 'PASS':\n",
    "                filtered_data = process_line(line)\n",
    "                write_to_output(output_file, filtered_data)\n",
    "\n",
    "def process_line(line):\n",
    "    chrom = line[vcf_columns_mapping['CHROM']]\n",
    "    position = line[vcf_columns_mapping['POS']]\n",
    "    rs_id = line[vcf_columns_mapping['ID']]\n",
    "    ref = line[vcf_columns_mapping['REF']]\n",
    "    alt = line[vcf_columns_mapping['ALT']]\n",
    "    population_data.update(get_population_data(line))\n",
    "    transcript_info = get_canonical_info(line)\n",
    "\n",
    "    filtered_data = [\n",
    "        chrom,\n",
    "        position,\n",
    "        rs_id,\n",
    "        ref,\n",
    "        alt,\n",
    "        population_data['AC'],\n",
    "        ', '.join(transcript_info['IMPACT']),\n",
    "        ', '.join(transcript_info['Consequence']),\n",
    "        ', '.join(transcript_info['SYMBOL']),\n",
    "        ', '.join(transcript_info['Feature']),\n",
    "        ', '.join(transcript_info['cDNA_position']),\n",
    "        ', '.join(transcript_info['LoF']),\n",
    "        ', '.join(transcript_info['LoF_flags']),\n",
    "        ', '.join(transcript_info['LoF_filter'])\n",
    "    ]\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "def get_population_data(line):\n",
    "    info_index = vcf_columns_mapping['INFO']\n",
    "    column_with_info = line[info_index].split(';')\n",
    "    data = {}\n",
    "    for element in column_with_info:\n",
    "        for category in population_data:\n",
    "            if element.startswith(f'{category}='):\n",
    "                frequency_value = element.split('=')\n",
    "                data[category] = frequency_value[-1]\n",
    "    return data\n",
    "\n",
    "def get_canonical_info(line):\n",
    "    transcript_info = {field: [] for field in ['IMPACT', 'Consequence', 'SYMBOL', 'Feature', 'cDNA_position', 'LoF', 'LoF_flags', 'LoF_filter']}\n",
    "    info_index = vcf_columns_mapping['INFO']\n",
    "    column_with_info = line[info_index].split(';')\n",
    "    vep_info = column_with_info[-1].split('|')\n",
    "    feature_index = vep_field_names.index('Feature')\n",
    "    canonical_index = vep_field_names.index('CANONICAL')\n",
    "    symbol_index = vep_field_names.index('SYMBOL')\n",
    "    step = 47\n",
    "\n",
    "    for i in range(feature_index, len(vep_info), step):\n",
    "        transcript = vep_info[i]\n",
    "        canonical = vep_info[i + canonical_index - feature_index]\n",
    "        symbol = vep_info[i + symbol_index - feature_index]\n",
    "\n",
    "        if symbol and transcript.startswith('ENST') and canonical:\n",
    "            for field in transcript_info:\n",
    "                field_index = vep_field_names.index(field)\n",
    "                info = vep_info[i + field_index - feature_index]\n",
    "                if info:\n",
    "                    if field == 'Feature' or field == 'CANONICAL':\n",
    "                        transcript_info[field].append(transcript)\n",
    "                    else:\n",
    "                        transcript_info[field].append(info)\n",
    "    return transcript_info\n",
    "\n",
    "def write_to_output(output_file, data):\n",
    "    with open(output_file, 'a', newline='', encoding='utf-8') as output_file:\n",
    "        tsv_writer = csv.writer(output_file, delimiter='\\t')\n",
    "        tsv_writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "290a7c67-b62e-429f-8789-52832626a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_vcf('../raw_data/example_22chr.vcf.bgz', output_filename='example_22chr.vcf_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff62976-4a1e-466d-a892-61df8415acdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0adc3328-3555-44fb-9c95-ea601418cc06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gzip\n",
    "import os\n",
    "\n",
    "# Column names for VCF file\n",
    "vcf_columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO']\n",
    "vcf_columns_dict = {col: idx for idx, col in enumerate(vcf_columns)}\n",
    "\n",
    "# Column names for VEP data\n",
    "vep_names = [\n",
    "    'Allele', 'Consequence', 'IMPACT', 'SYMBOL', 'Gene', 'Feature_type', 'Feature', 'BIOTYPE',\n",
    "    'EXON', 'INTRON', 'HGVSc', 'HGVSp', 'cDNA_position', 'CDS_position', 'Protein_position',\n",
    "    'Amino_acids', 'Codons', 'ALLELE_NUM', 'DISTANCE', 'STRAND', 'FLAGS', 'VARIANT_CLASS',\n",
    "    'SYMBOL_SOURCE', 'HGNC_ID', 'CANONICAL', 'MANE_SELECT', 'MANE_PLUS_CLINICAL', 'TSL', 'APPRIS',\n",
    "    'CCDS', 'ENSP', 'UNIPROT_ISOFORM', 'SOURCE', '', '', 'DOMAINS', 'miRNA', 'HGVS_OFFSET',\n",
    "    'PUBMED', 'MOTIF_NAME', 'MOTIF_POS', 'HIGH_INF_POS', 'MOTIF_SCORE_CHANGE', 'TRANSCRIPTION_FACTORS',\n",
    "    'LoF', 'LoF_filter', 'LoF_flags', 'LoF_info'\n",
    "]\n",
    "vep_dict = {name: idx for idx, name in enumerate(vep_names)}\n",
    "\n",
    "# Column names for population data\n",
    "population_data = (\n",
    "    'AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', 'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "    'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "    'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin'\n",
    ")\n",
    "population_dict = {pop: idx for idx, pop in enumerate(population_data)}\n",
    "\n",
    "# Headers for the output TSV file\n",
    "headers = [\n",
    "    'Chr', 'Position', 'rsID', 'Ref', 'Alt', 'AC', 'Impact', 'Consequence',\n",
    "    'Gene_symbol', 'Canonical_transcript', 'cDNA_position', 'LoF', 'LoF_flag', 'LoF_filter'\n",
    "]\n",
    "\n",
    "def parse_vcf(vcf_file, output_dir='', output_filename=''):\n",
    "    if output_dir == '':\n",
    "        output_dir = os.getcwd()\n",
    "\n",
    "    if output_filename == '':\n",
    "        output_filename = os.path.splitext(os.path.basename(vcf_file))[0] + '.tsv'\n",
    "    else:\n",
    "        if not output_filename.endswith('.tsv'):\n",
    "            output_filename += '.tsv'\n",
    "\n",
    "    output_file = os.path.join(output_dir, output_filename)\n",
    "\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as table_file:\n",
    "        writer = csv.writer(table_file, delimiter='\\t')\n",
    "        writer.writerow(headers)\n",
    "\n",
    "    with gzip.open(vcf_file, 'rt') as input_file, open(output_file, 'a', newline='', encoding='utf-8') as output_file:\n",
    "        vcf_reader = csv.reader(input_file, delimiter='\\t')\n",
    "        tsv_writer = csv.writer(output_file, delimiter='\\t')\n",
    "        \n",
    "        for line in vcf_reader:\n",
    "            parsed_data = parse_line(line)\n",
    "            for data in parsed_data:\n",
    "                tsv_writer.writerow(data)\n",
    "\n",
    "\n",
    "def parse_line(line):\n",
    "    parsed_data = []\n",
    "\n",
    "    if line[vcf_columns_dict['CHROM']].startswith('chr') and line[vcf_columns_dict['FILTER']] == 'PASS':\n",
    "        chrom = line[vcf_columns_dict['CHROM']]\n",
    "        position = line[vcf_columns_dict['POS']]\n",
    "        rs_id = line[vcf_columns_dict['ID']]\n",
    "        ref = line[vcf_columns_dict['REF']]\n",
    "        alt = line[vcf_columns_dict['ALT']]\n",
    "\n",
    "        # Extract population data\n",
    "        info = line[vcf_columns_dict['INFO']].split(';')\n",
    "        for element in info:\n",
    "            for pop in population_dict:\n",
    "                if element.startswith(f'{pop}='):\n",
    "                    population_dict[pop] = element.split('=')[-1] \n",
    "            \n",
    "        # Extract VEP info\n",
    "        vep_info = info[-1].split(',')\n",
    "        for variant in vep_info:\n",
    "            variant = variant.split('|')\n",
    "            for column_name, _ in vep_dict.items():\n",
    "                vep_field_index = vep_names.index(column_name)\n",
    "                vep_dict[column_name] = variant[vep_field_index]\n",
    "\n",
    "            if vep_dict['SYMBOL'] and vep_dict['Feature'].startswith('ENST') and vep_dict['CANONICAL']:\n",
    "                filtered_data = [\n",
    "                    chrom, position, rs_id, ref, alt, population_dict['AC'],\n",
    "                    vep_dict['IMPACT'], vep_dict['Consequence'], vep_dict['SYMBOL'], \n",
    "                    vep_dict['Feature'], vep_dict['cDNA_position'], \n",
    "                    vep_dict['LoF'], vep_dict['LoF_filter'], vep_dict['LoF_flags']\n",
    "                ]\n",
    "                parsed_data.append(filtered_data)\n",
    "\n",
    "    return parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "923c8d10-9b52-4ee1-bd80-e8ae28fff6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_parse_vcf('../raw_data/example_22chr.vcf.bgz', output_filename='example_22chr.vcf_new_2')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bi_kernel",
   "language": "python",
   "name": "bi_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
