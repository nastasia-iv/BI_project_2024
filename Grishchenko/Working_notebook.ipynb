{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bc102eb-fd66-46a4-8e6f-c43b16c25e76",
   "metadata": {},
   "source": [
    "## Collecting data from gnomAD\n",
    "\n",
    "Variants data downloaded from [gnomAD](https://gnomad.broadinstitute.org/downloads#v4)\n",
    "\n",
    "Use command line for initial processing\n",
    "\n",
    "1. Filtered only PASS variants \n",
    "\n",
    "```zsh\n",
    "bcftools view -f 'PASS,.' gnomad.exomes.v4.0.sites.chr22.vcf.bgz > filtered_gnomad22.bgz\n",
    "```\n",
    "For next parcing we can use also **command line** or **python**\n",
    "\n",
    "2. Extract the necessary data\n",
    "\n",
    "for this step we need **bcftools** utility\n",
    "\n",
    "```zsh\n",
    "bcftools query -f '%CHROM\\t%POS\\t%ID\\t%REF\\t%ALT\\t%AC\\t%AC_afr\\t%AC_amr\\t%AC_nfe\n",
    "\\t%AC_asj\\t%AC_sas\\t%AC_eas\\t%AC_mid\\t%AC_fin\\t%AN\\t%AN_afr\\t%AN_amr\\t%AN_nfe\\t%AN_asj\n",
    "\\t%AN_sas\\t%AN_eas\\t%AN_mid\\t%AN_fin\\t%AF\\t%AF_afr\\t%AF_amr\\t%AF_nfe\\t%AF_asj\\t%AF_sas\n",
    "\\t%AF_eas\\t%AF_mid\\t%AF_fin\\t%vep=\\n' filtered_gnomad22.bgz > processed_gnomad22.vcf.bgz\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f204f7-7119-43ad-95f8-6a50766edd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "import cyvcf2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variant \u001b[38;5;129;01min\u001b[39;00m vcf:\n\u001b[1;32m     27\u001b[0m     variant_data \u001b[38;5;241m=\u001b[39m [variant\u001b[38;5;241m.\u001b[39mCHROM, variant\u001b[38;5;241m.\u001b[39mPOS, variant\u001b[38;5;241m.\u001b[39mID, variant\u001b[38;5;241m.\u001b[39mREF, variant\u001b[38;5;241m.\u001b[39mALT[\u001b[38;5;241m0\u001b[39m]]\n\u001b[0;32m---> 28\u001b[0m     info_data \u001b[38;5;241m=\u001b[39m [\u001b[43mvariant\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfield\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m field \u001b[38;5;129;01min\u001b[39;00m info_fields_to_extract]\n\u001b[1;32m     29\u001b[0m     vep_annotation \u001b[38;5;241m=\u001b[39m variant\u001b[38;5;241m.\u001b[39mINFO\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvep\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Handle multiple transcripts in vep if present\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "vcf_path = 'data/gnomad.exomes.v4.0.sites.chr22.vcf.bgz'\n",
    "vcf = cyvcf2.VCF(vcf_path)\n",
    "\n",
    "# Define the columns to extract\n",
    "info_fields_to_extract = ['AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', 'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "               'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "               'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin', 'vep']\n",
    "vep_field_mapping = {\n",
    "        1: 'Consequence', 3: 'SYMBOL',\n",
    "        5: 'Feature_Type', 6: 'Feature', 7: 'BIOTYPE', 8: 'EXON', 9: 'INTRON',\n",
    "        17: 'ALLELE_NUM', 24: 'CANONICAL',\n",
    "        42: 'LoF', 43: 'LoF_filter', 44: 'LoF_flags', 45: 'LoF_info'}\n",
    "\n",
    "column_names = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', \n",
    "                'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "                'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "                'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin',\n",
    "                'Consequence', 'SYMBOL', 'Feature_Type', 'Feature', 'BIOTYPE', 'EXON', 'INTRON', 'ALLELE_NUM',\n",
    "                'CANONICAL', 'LoF', 'LoF_filter', 'LoF_flags', 'LoF_info']\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate over each variant in the VCF file\n",
    "counter = 1\n",
    "for variant in vcf:\n",
    "    variant_data = [variant.CHROM, variant.POS, variant.ID, variant.REF, variant.ALT[0]]\n",
    "    info_data = [variant.INFO.get(field, '.') for field in info_fields_to_extract]\n",
    "    vep_annotation = variant.INFO.get('vep')\n",
    "\n",
    "    # Handle multiple transcripts in vep if present\n",
    "    if vep_annotation:\n",
    "        vep_transcripts = vep_annotation.split(',')\n",
    "        for transcript in vep_transcripts:\n",
    "            split_transcript = transcript.split('|')\n",
    "            vep_fields = []\n",
    "            for key in vep_field_mapping.keys():\n",
    "                try:\n",
    "                    vep_fields.append(split_transcript[key])\n",
    "                except:\n",
    "                    vep_fields.append('.')\n",
    "            data.append(variant_data + info_data[:-1] + vep_fields)\n",
    "    else:\n",
    "        data.append(variant_data + info_data + ['.'])\n",
    "    counter += 1\n",
    "output_file_name = f\"output_{vcf_path.split('.')[-3]}.tsv\"\n",
    "with open(output_file_name, 'w', newline='') as tsvfile:\n",
    "    writer = csv.writer(tsvfile, delimiter='\\t')\n",
    "    # Write the header\n",
    "    writer.writerow(column_names)\n",
    "    # Write the data rows\n",
    "    writer.writerows(data)\n",
    "# Create a pandas DataFrame from the extracted data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22426cf5",
   "metadata": {},
   "source": [
    "Проверка на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3475fb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vcf_path = 'data/test.bgz'\n",
    "vcf = cyvcf2.VCF(vcf_path)\n",
    "\n",
    "# Define the columns to extract\n",
    "info_fields_to_extract = ['AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', 'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "               'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "               'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin', 'vep']\n",
    "vep_field_mapping = {\n",
    "        1: 'Consequence', 3: 'SYMBOL',\n",
    "        5: 'Feature_Type', 6: 'Feature', 7: 'BIOTYPE', 8: 'EXON', 9: 'INTRON',\n",
    "        17: 'ALLELE_NUM', 21: 'VARIANT_CLASS', 24: 'CANONICAL',\n",
    "        42: 'LoF', 43: 'LoF_filter', 44: 'LoF_flags', 45: 'LoF_info'}\n",
    "\n",
    "column_names = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'AC', 'AC_afr', 'AC_amr', 'AC_nfe', 'AC_asj', \n",
    "                'AC_sas', 'AC_eas', 'AC_mid', 'AC_fin',\n",
    "                'AN', 'AN_afr', 'AN_amr', 'AN_nfe', 'AN_asj', 'AN_sas', 'AN_eas', 'AN_mid', 'AN_fin',\n",
    "                'AF', 'AF_afr', 'AF_amr', 'AF_nfe', 'AF_asj', 'AF_sas', 'AF_eas', 'AF_mid', 'AF_fin',\n",
    "                'Consequence', 'SYMBOL', 'Feature_Type', 'Feature', 'BIOTYPE', 'EXON', 'INTRON', 'ALLELE_NUM',\n",
    "                'VARIANT_CLASS', 'CANONICAL', 'LoF', 'LoF_filter', 'LoF_flags', 'LoF_info']\n",
    "\n",
    "# Initialize an empty list to store the extracted data\n",
    "data = []\n",
    "\n",
    "# Iterate over each variant in the VCF file\n",
    "counter = 1\n",
    "for variant in vcf:\n",
    "    variant_data = [variant.CHROM, variant.POS, variant.ID, variant.REF, variant.ALT[0]]\n",
    "    info_data = [variant.INFO.get(field, '.') for field in info_fields_to_extract]\n",
    "    vep_annotation = variant.INFO.get('vep')\n",
    "\n",
    "    # Handle multiple transcripts in vep if present\n",
    "    if vep_annotation:\n",
    "        vep_transcripts = vep_annotation.split(',')\n",
    "        for transcript in vep_transcripts:\n",
    "            split_transcript = transcript.split('|')\n",
    "            vep_fields = []\n",
    "            for key in vep_field_mapping.keys():\n",
    "                try:\n",
    "                    vep_fields.append(split_transcript[key])\n",
    "                except:\n",
    "                    vep_fields.append('.')\n",
    "            data.append(variant_data + info_data[:-1] + vep_fields)\n",
    "    else:\n",
    "        data.append(variant_data + info_data + ['.'])\n",
    "    counter += 1\n",
    "vcf_df = pd.DataFrame(data, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bcbecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SNV', 'insertion', 'deletion', '.'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vcf_df['VARIANT_CLASS'].unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BI_main_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
